{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lpips\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Configuring directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "distorted_images_dir = \"Distortions_v2\"\n",
    "csv_output_dir = \"CSVs\"\n",
    "chart_output_dir = \"Charts\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Measuring values and saving to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LPIPS model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loss_fn = lpips.LPIPS(net='alex').to(device)\n",
    "\n",
    "# Transform: convert image to tensor and normalize to [-1, 1]\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Optional: adjust to match your data\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)  # LPIPS expects input in [-1, 1]\n",
    "])\n",
    "\n",
    "results = []\n",
    "\n",
    "# Loop over picture folders (Degus, Hotdog, etc.)\n",
    "for scene_folder in os.listdir(distorted_images_dir):\n",
    "    scene_path = os.path.join(distorted_images_dir, scene_folder)\n",
    "    if not os.path.isdir(scene_path):\n",
    "        continue\n",
    "\n",
    "    # Loop over distortion type folders (Blur, Noise, etc.)\n",
    "    for distortion_folder in os.listdir(scene_path):\n",
    "        distortion_path = os.path.join(scene_path, distortion_folder)\n",
    "        if not os.path.isdir(distortion_path):\n",
    "            continue\n",
    "\n",
    "        # Find ref image (ends with 0.bmp and is only .bmp file)\n",
    "        reference_image = None\n",
    "        for file in os.listdir(distortion_path):\n",
    "            if file.endswith('_0.bmp'):\n",
    "                reference_image = os.path.join(distortion_path, file)\n",
    "                break\n",
    "        if reference_image is None:\n",
    "            print(f\"No reference image found in {scene_path}\")\n",
    "            continue\n",
    "        ref_img = transform(Image.open(reference_image).convert('RGB')).unsqueeze(0).to(device)\n",
    "\n",
    "        # Calculate lpips for each picture\n",
    "        for file in os.listdir(distortion_path):\n",
    "            if not file.endswith('.bmp') and not file.endswith('.png'):\n",
    "                continue\n",
    "\n",
    "            distorted_image_path = os.path.join(distortion_path, file)\n",
    "\n",
    "            # Load and preprocess distorted image\n",
    "            dist_img = transform(Image.open(distorted_image_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "\n",
    "            # Compute LPIPS distance\n",
    "            with torch.no_grad():\n",
    "                distance = loss_fn(ref_img, dist_img).item()\n",
    "\n",
    "            #extract distortion value\n",
    "            distortion_value = -1\n",
    "            match = re.search(r'^([^_]+)_([^_]+)_(.*)\\.(png|bmp)$', file)\n",
    "            try:\n",
    "                distortion_value = float(match.group(3))\n",
    "            except:\n",
    "                print(f\"No distortion value found in {file}\")\n",
    "\n",
    "            # Save result\n",
    "            results.append({\n",
    "                'Picture': scene_folder,\n",
    "                'DistortionType': distortion_folder,\n",
    "                'DistortionValue': distortion_value,\n",
    "                'Filename': file,\n",
    "                'LPIPS': distance\n",
    "            })\n",
    "\n",
    "# Save all results to CSV\n",
    "df = pd.DataFrame(results)\n",
    "os.makedirs(csv_output_dir, exist_ok=True)\n",
    "df.to_csv(csv_output_dir + '/lpips_distortion_results.csv', index=False)\n",
    "print(\"✅ Results saved to lpips_distortion_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Creating charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load CSV ===\n",
    "df = pd.read_csv(csv_output_dir + \"/lpips_distortion_results.csv\")\n",
    "\n",
    "# Add synthetic LPIPS=0 for level 0 reference images\n",
    "reference_rows = []\n",
    "for picture in df['Picture'].unique():\n",
    "    for distortion in df['DistortionType'].unique():\n",
    "        reference_rows.append({\n",
    "            'Picture': picture,\n",
    "            'DistortionType': distortion,\n",
    "            'DistortionValue': 0,\n",
    "            'Filename': 'image_0.bmp',\n",
    "            'LPIPS': 0.0\n",
    "        })\n",
    "\n",
    "df = pd.concat([df, pd.DataFrame(reference_rows)], ignore_index=True)\n",
    "\n",
    "# === Plotting ===\n",
    "os.makedirs(chart_output_dir, exist_ok=True)\n",
    "\n",
    "for distortion in df['DistortionType'].unique():\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    distortion_df = df[df['DistortionType'] == distortion]\n",
    "\n",
    "    for picture in sorted(distortion_df['Picture'].unique()):\n",
    "        picture_df = distortion_df[distortion_df['Picture'] == picture]\n",
    "        picture_df = picture_df.sort_values('DistortionValue')\n",
    "\n",
    "        # Build y and x values\n",
    "        x = picture_df['DistortionValue']\n",
    "        y = picture_df['LPIPS']\n",
    "        plt.plot(x, y, marker='o', label=picture)\n",
    "\n",
    "    plt.title(f'LPIPS vs Distortion Value – {distortion}')\n",
    "    plt.xlabel('Distortion Parameter')\n",
    "    plt.ylabel('LPIPS Distance')\n",
    "    plt.legend(title='Picture', fontsize='small')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{chart_output_dir}/{distortion}_lpips_chart.png')\n",
    "    plt.close()\n",
    "\n",
    "print(\"✅ All charts saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Creating group chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === Load CSV and filter for _4.bmp ===\n",
    "# df = pd.read_csv(csv_output_dir + \"/lpips_distortion_results.csv\")\n",
    "# df = df[df['Filename'].str.endswith('_4.bmp')]\n",
    "# df['Level'] = 4\n",
    "#\n",
    "# # === Parse level 4 descriptions from markdown ===\n",
    "# def parse_md_level_4_descriptions(md_path):\n",
    "#     with open(md_path, 'r') as f:\n",
    "#         lines = f.readlines()\n",
    "#\n",
    "#     descriptions = {}\n",
    "#     current_type = None\n",
    "#     for line in lines:\n",
    "#         line = line.strip()\n",
    "#         if line.startswith(\"##\"):\n",
    "#             header = line[2:].strip()\n",
    "#             match = re.match(r'\\d+\\.\\s*([^\\(]+)', header)\n",
    "#             if match:\n",
    "#                 current_type = match.group(1).strip()\n",
    "#         elif line.startswith(\"- Level 4:\") and current_type:\n",
    "#             desc = line.split(\":\", 1)[1].strip()\n",
    "#             descriptions[current_type] = desc\n",
    "#     return descriptions\n",
    "#\n",
    "# desc_mapping = parse_md_level_4_descriptions(\"Image distorion Description.md\")\n",
    "#\n",
    "# # === Clean distortion names and attach descriptions ===\n",
    "# df['DistortionTypeClean'] = df['DistortionType'].str.strip()\n",
    "# df['Description'] = df['DistortionTypeClean'].map(desc_mapping)\n",
    "# df['Label'] = df.apply(\n",
    "#     lambda row: f\"{row['DistortionTypeClean']} ({row['Description']})\" if pd.notnull(row['Description']) else row['DistortionTypeClean'],\n",
    "#     axis=1\n",
    "# )\n",
    "#\n",
    "# # === Get unique distortions and scenes ===\n",
    "# distortions = sorted(df['Label'].unique())\n",
    "# scenes = sorted(df['Scene'].unique())\n",
    "#\n",
    "# # === Prepare grouped bar chart data ===\n",
    "# bar_width = 0.8 / len(scenes)  # fit all scene bars per group\n",
    "# x = np.arange(len(distortions))  # X positions for each group\n",
    "#\n",
    "# colors = plt.cm.tab10.colors\n",
    "# fig, ax = plt.subplots(figsize=(14, 6))\n",
    "#\n",
    "# # Plot bars per scene\n",
    "# for i, picture in enumerate(scenes):\n",
    "#     heights = []\n",
    "#     for dist in distortions:\n",
    "#         match = df[(df['Label'] == dist) & (df['Scene'] == picture)]\n",
    "#         heights.append(match['LPIPS'].values[0] if not match.empty else 0)\n",
    "#\n",
    "#     ax.bar(x + i * bar_width, heights, bar_width, label=picture, color=colors[i % len(colors)])\n",
    "#\n",
    "# # === Final plot formatting ===\n",
    "# ax.set_xticks(x + bar_width * (len(scenes) - 1) / 2)\n",
    "# ax.set_xticklabels(distortions, rotation=45, ha='right')\n",
    "# ax.set_ylabel(\"LPIPS Distance\")\n",
    "# ax.set_title(\"LPIPS Scores at Distortion Level 4 (Grouped by Distortion Type)\")\n",
    "# ax.legend(title=\"Scene\")\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"charts/bar_chart_level4_grouped_by_distortion.png\")\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
