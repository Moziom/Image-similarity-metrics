{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T13:41:17.911078Z",
     "start_time": "2025-06-03T13:41:07.314571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import lpips\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ],
   "id": "a181d1548ddeae82",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Measuring values and saving to csv file",
   "id": "530c2560581ce042"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T13:41:40.515626Z",
     "start_time": "2025-06-03T13:41:18.450855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize LPIPS model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loss_fn = lpips.LPIPS(net='alex').to(device)\n",
    "\n",
    "# Transform: convert image to tensor and normalize to [-1, 1]\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Optional: adjust to match your data\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)  # LPIPS expects input in [-1, 1]\n",
    "])\n",
    "\n",
    "root_dir = 'Distortions'\n",
    "results = []\n",
    "\n",
    "for scene_folder in os.listdir(root_dir):\n",
    "    scene_path = os.path.join(root_dir, scene_folder)\n",
    "    if not os.path.isdir(scene_path):\n",
    "        continue\n",
    "\n",
    "    # Find the reference image (ends with '0.bmp')\n",
    "    reference_image = None\n",
    "    for file in os.listdir(scene_path):\n",
    "        if file.endswith('_0.bmp'):\n",
    "            reference_image = os.path.join(scene_path, file)\n",
    "            break\n",
    "\n",
    "    if reference_image is None:\n",
    "        print(f\"No reference image found in {scene_path}\")\n",
    "        continue\n",
    "\n",
    "    ref_img = transform(Image.open(reference_image).convert('RGB')).unsqueeze(0).to(device)\n",
    "\n",
    "    # Loop over distortion type folders (Blur, Noise, etc.)\n",
    "    for distortion_folder in os.listdir(scene_path):\n",
    "        distortion_path = os.path.join(scene_path, distortion_folder)\n",
    "        if not os.path.isdir(distortion_path):\n",
    "            continue\n",
    "\n",
    "        for file in os.listdir(distortion_path):\n",
    "            if not file.endswith('.bmp'):\n",
    "                continue\n",
    "\n",
    "            distorted_image_path = os.path.join(distortion_path, file)\n",
    "\n",
    "            # Load and preprocess distorted image\n",
    "            dist_img = transform(Image.open(distorted_image_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "\n",
    "            # Compute LPIPS distance\n",
    "            with torch.no_grad():\n",
    "                distance = loss_fn(ref_img, dist_img).item()\n",
    "\n",
    "            # Save result\n",
    "            results.append({\n",
    "                'Scene': scene_folder,\n",
    "                'DistortionType': distortion_folder,\n",
    "                'Filename': file,\n",
    "                'LPIPS': distance\n",
    "            })\n",
    "\n",
    "# Save all results to CSV\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv('lpips_distortion_results.csv', index=False)\n",
    "print(\"✅ Results saved to lpips_distortion_results.csv\")"
   ],
   "id": "d140094b6ed36761",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nocto\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Nocto\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: C:\\Users\\Nocto\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\lpips\\weights\\v0.1\\alex.pth\n",
      "✅ Results saved to lpips_distortion_results.csv\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creating charts",
   "id": "5f734c57e1a134ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T13:41:44.066796Z",
     "start_time": "2025-06-03T13:41:41.716500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === Load CSV ===\n",
    "df = pd.read_csv(\"lpips_distortion_results.csv\")\n",
    "\n",
    "# Extract numeric distortion level from filename\n",
    "def extract_level(filename):\n",
    "    match = re.search(r'_(\\d+)\\.bmp$', filename)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "df['Level'] = df['Filename'].apply(extract_level)\n",
    "df = df.dropna(subset=['Level'])\n",
    "df['Level'] = df['Level'].astype(int)\n",
    "\n",
    "# === Parse Markdown for level-to-value mapping ===\n",
    "def parse_md_description(md_path):\n",
    "    with open(md_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    mapping = {}\n",
    "    current_type = None\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "\n",
    "        if line.startswith(\"##\"):\n",
    "            header = line[2:].strip()\n",
    "            # Remove number and any parentheses\n",
    "            match = re.match(r'\\d+\\.\\s*([^(]+)', header)\n",
    "            if match:\n",
    "                current_type = match.group(1).strip()\n",
    "                mapping[current_type] = {}\n",
    "        elif line.startswith(\"- Level\"):\n",
    "            match = re.match(r\"- Level (\\d+): (.+)\", line)\n",
    "            if match and current_type:\n",
    "                level = int(match.group(1))\n",
    "                desc = match.group(2).strip()\n",
    "                mapping[current_type][level] = desc\n",
    "    return mapping\n",
    "\n",
    "desc_mapping = parse_md_description(\"Image distorion Description.md\")\n",
    "\n",
    "# Add synthetic LPIPS=0 for level 0 reference images\n",
    "reference_rows = []\n",
    "for scene in df['Scene'].unique():\n",
    "    for distortion in df['DistortionType'].unique():\n",
    "        reference_rows.append({\n",
    "            'Scene': scene,\n",
    "            'DistortionType': distortion,\n",
    "            'Filename': 'image_0.bmp',\n",
    "            'LPIPS': 0.0,\n",
    "            'Level': 0\n",
    "        })\n",
    "\n",
    "df = pd.concat([df, pd.DataFrame(reference_rows)], ignore_index=True)\n",
    "\n",
    "# === Plotting ===\n",
    "output_dir = \"charts\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for distortion in df['DistortionType'].unique():\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    distortion_df = df[df['DistortionType'] == distortion]\n",
    "\n",
    "    # Get value mapping\n",
    "    value_map = desc_mapping.get(distortion, {})\n",
    "    x_vals = [0] + [value_map.get(i, str(i)) for i in range(1, 5)]\n",
    "\n",
    "    # For consistent X-axis order\n",
    "    x_vals_str = [str(v) for v in x_vals]\n",
    "\n",
    "    for scene in sorted(distortion_df['Scene'].unique()):\n",
    "        scene_df = distortion_df[distortion_df['Scene'] == scene]\n",
    "        scene_df = scene_df.groupby('Level')['LPIPS'].mean().sort_index()\n",
    "\n",
    "        # Build y and x values\n",
    "        y = [scene_df.get(lvl, None) for lvl in range(0, 5)]\n",
    "        plt.plot(x_vals_str, y, marker='o', label=scene)\n",
    "\n",
    "    plt.title(f'LPIPS vs Distortion Value – {distortion}')\n",
    "    plt.xlabel('Distortion Parameter')\n",
    "    plt.ylabel('LPIPS Distance')\n",
    "    plt.legend(title='Scene', fontsize='small')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/{distortion}_lpips_multiscene_chart.png')\n",
    "    plt.close()\n",
    "\n",
    "print(\"✅ All charts saved in 'charts/' with correct labels and scene-wise lines.\")"
   ],
   "id": "3024e04b66204942",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All charts saved in 'charts/' with correct labels and scene-wise lines.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creating group chart",
   "id": "5a09e055fb968c9e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# === Load CSV and filter for _4.bmp ===\n",
    "df = pd.read_csv(\"lpips_distortion_results.csv\")\n",
    "df = df[df['Filename'].str.endswith('_4.bmp')]\n",
    "df['Level'] = 4\n",
    "\n",
    "# === Parse level 4 descriptions from markdown ===\n",
    "def parse_md_level_4_descriptions(md_path):\n",
    "    with open(md_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    descriptions = {}\n",
    "    current_type = None\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"##\"):\n",
    "            header = line[2:].strip()\n",
    "            match = re.match(r'\\d+\\.\\s*([^\\(]+)', header)\n",
    "            if match:\n",
    "                current_type = match.group(1).strip()\n",
    "        elif line.startswith(\"- Level 4:\") and current_type:\n",
    "            desc = line.split(\":\", 1)[1].strip()\n",
    "            descriptions[current_type] = desc\n",
    "    return descriptions\n",
    "\n",
    "desc_mapping = parse_md_level_4_descriptions(\"Image distorion Description.md\")\n",
    "\n",
    "# === Clean distortion names and attach descriptions ===\n",
    "df['DistortionTypeClean'] = df['DistortionType'].str.strip()\n",
    "df['Description'] = df['DistortionTypeClean'].map(desc_mapping)\n",
    "df['Label'] = df.apply(\n",
    "    lambda row: f\"{row['DistortionTypeClean']} ({row['Description']})\" if pd.notnull(row['Description']) else row['DistortionTypeClean'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# === Get unique distortions and scenes ===\n",
    "distortions = sorted(df['Label'].unique())\n",
    "scenes = sorted(df['Scene'].unique())\n",
    "\n",
    "# === Prepare grouped bar chart data ===\n",
    "bar_width = 0.8 / len(scenes)  # fit all scene bars per group\n",
    "x = np.arange(len(distortions))  # X positions for each group\n",
    "\n",
    "colors = plt.cm.tab10.colors\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Plot bars per scene\n",
    "for i, scene in enumerate(scenes):\n",
    "    heights = []\n",
    "    for dist in distortions:\n",
    "        match = df[(df['Label'] == dist) & (df['Scene'] == scene)]\n",
    "        heights.append(match['LPIPS'].values[0] if not match.empty else 0)\n",
    "\n",
    "    ax.bar(x + i * bar_width, heights, bar_width, label=scene, color=colors[i % len(colors)])\n",
    "\n",
    "# === Final plot formatting ===\n",
    "ax.set_xticks(x + bar_width * (len(scenes) - 1) / 2)\n",
    "ax.set_xticklabels(distortions, rotation=45, ha='right')\n",
    "ax.set_ylabel(\"LPIPS Distance\")\n",
    "ax.set_title(\"LPIPS Scores at Distortion Level 4 (Grouped by Distortion Type)\")\n",
    "ax.legend(title=\"Scene\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"charts/bar_chart_level4_grouped_by_distortion.png\")\n",
    "plt.show()\n"
   ],
   "id": "b801bdae068e1bf3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
