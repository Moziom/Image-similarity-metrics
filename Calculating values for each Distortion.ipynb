{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lpips\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from skimage.metrics import structural_similarity as ssim_skimage\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from torchmetrics.image import UniversalImageQualityIndex\n",
    "from torchmetrics.image import VisualInformationFidelity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "distorted_images_dir = \"Distortions_v2\"\n",
    "csv_output_dir = \"CSVs\"\n",
    "chart_output_dir = \"Charts\"\n",
    "\n",
    "recalculate_values = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Measuring values and saving to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'CSVs/distortion_results.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_output_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/distortion_results.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m scene_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDegus\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m distortion_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlur\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'CSVs/distortion_results.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(csv_output_dir + \"/distortion_results.csv\")\n",
    "scene_folder = \"Degus\"\n",
    "distortion_folder = \"Blur\"\n",
    "distortion_value = 1\n",
    "df_i = df[\n",
    "                    (df[\"Picture\"] == scene_folder) &\n",
    "                    (df[\"DistortionType\"] == distortion_folder) &\n",
    "                    (df[\"DistortionValue\"] == distortion_value)\n",
    "                ]\n",
    "print(df_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81147ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "def cal_ssim(img1, img2):\n",
    "\n",
    "    K = [0.01, 0.03]\n",
    "    L = 255\n",
    "    kernelX = cv2.getGaussianKernel(11, 1.5)\n",
    "    window = kernelX * kernelX.T\n",
    "\n",
    "    M,N = np.shape(img1)\n",
    "\n",
    "    C1 = (K[0]*L)**2\n",
    "    C2 = (K[1]*L)**2\n",
    "    img1 = np.float64(img1)\n",
    "    img2 = np.float64(img2)\n",
    "\n",
    "    mu1 = signal.convolve2d(img1, window, 'valid')\n",
    "    mu2 = signal.convolve2d(img2, window, 'valid')\n",
    "\n",
    "    mu1_sq = mu1*mu1\n",
    "    mu2_sq = mu2*mu2\n",
    "    mu1_mu2 = mu1*mu2\n",
    "\n",
    "\n",
    "    sigma1_sq = signal.convolve2d(img1*img1, window, 'valid') - mu1_sq\n",
    "    sigma2_sq = signal.convolve2d(img2*img2, window, 'valid') - mu2_sq\n",
    "    sigma12 = signal.convolve2d(img1*img2, window, 'valid') - mu1_mu2\n",
    "\n",
    "    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n",
    "    mssim = np.mean(ssim_map)\n",
    "    return mssim,ssim_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: C:\\Users\\piotr\\AppData\\Roaming\\Python\\Python312\\site-packages\\lpips\\weights\\v0.1\\alex.pth\n",
      "Degus\n",
      "Blur\n",
      "Degus_blur_0.bmp\n",
      "Degus_blur_1.png\n",
      "Degus_blur_10.png\n",
      "Degus_blur_12_5.png\n",
      "Degus_blur_15.png\n",
      "Degus_blur_2.png\n",
      "Degus_blur_3.png\n",
      "Degus_blur_5.png\n",
      "Degus_blur_7_5.png\n",
      "Brightness\n",
      "Degus_brightness_0.bmp\n",
      "Degus_brightness_1_02.png\n",
      "Degus_brightness_1_05.png\n",
      "Degus_brightness_1_1.png\n",
      "Degus_brightness_1_2.png\n",
      "Degus_brightness_1_5.png\n",
      "Degus_brightness_1_75.png\n",
      "Degus_brightness_2.png\n",
      "Degus_brightness_2_25.png\n",
      "Circularblur\n",
      "Degus_circularBlur_0.bmp\n",
      "Degus_circularBlur_1.png\n",
      "Degus_circularBlur_10.png\n",
      "Degus_circularBlur_2.png\n",
      "Degus_circularBlur_3.png\n",
      "Degus_circularBlur_4.png\n",
      "Degus_circularBlur_5.png\n",
      "Degus_circularBlur_7_5.png\n",
      "Dilation\n",
      "Degus_dilation_0.bmp\n",
      "Degus_dilation_1.png\n",
      "Degus_dilation_2.png\n",
      "Degus_dilation_3.png\n",
      "Degus_dilation_4.png\n",
      "Degus_dilation_5.png\n",
      "Hole\n",
      "Degus_hole_0.bmp\n",
      "Degus_hole_0_01.png\n",
      "Degus_hole_0_05.png\n",
      "Degus_hole_0_1.png\n",
      "Degus_hole_0_15.png\n",
      "Degus_hole_0_2.png\n",
      "Degus_hole_0_3.png\n",
      "Degus_hole_0_4.png\n",
      "Noise\n",
      "Degus_noise_0.bmp\n",
      "Degus_noise_1.png\n",
      "Degus_noise_10.png\n",
      "Degus_noise_2.png\n",
      "Degus_noise_20.png\n",
      "Degus_noise_35.png\n",
      "Degus_noise_5.png\n",
      "Degus_noise_50.png\n",
      "Rotate\n",
      "Degus_rotate_0.bmp\n",
      "Degus_rotate_1.png\n",
      "Degus_rotate_10.png\n",
      "Degus_rotate_15.png\n",
      "Degus_rotate_2.png\n",
      "Degus_rotate_20.png\n",
      "Degus_rotate_3.png\n",
      "Degus_rotate_35.png\n",
      "Degus_rotate_5.png\n",
      "Saturation\n",
      "Degus_saturation_0.bmp\n",
      "Degus_saturation_1_05.png\n",
      "Degus_saturation_1_1.png\n",
      "Degus_saturation_1_15.png\n",
      "Degus_saturation_1_2.png\n",
      "Degus_saturation_1_5.png\n",
      "Degus_saturation_1_75.png\n",
      "Degus_saturation_2.png\n",
      "Shift\n",
      "Degus_shift_0.bmp\n",
      "Degus_shift_0_01.png\n",
      "Degus_shift_0_02.png\n",
      "Degus_shift_0_05.png\n",
      "Degus_shift_0_1.png\n",
      "Degus_shift_0_2.png\n",
      "Degus_shift_0_3.png\n",
      "Hotdog\n",
      "Blur\n",
      "Hotdog_blur_0.bmp\n",
      "Hotdog_blur_1.png\n",
      "Hotdog_blur_10.png\n",
      "Hotdog_blur_12_5.png\n",
      "Hotdog_blur_15.png\n",
      "Hotdog_blur_2.png\n",
      "Hotdog_blur_3.png\n",
      "Hotdog_blur_5.png\n",
      "Hotdog_blur_7_5.png\n",
      "Brightness\n",
      "Hotdog_brightness_0.bmp\n",
      "Hotdog_brightness_1_02.png\n",
      "Hotdog_brightness_1_05.png\n",
      "Hotdog_brightness_1_1.png\n",
      "Hotdog_brightness_1_2.png\n",
      "Hotdog_brightness_1_5.png\n",
      "Hotdog_brightness_1_75.png\n",
      "Hotdog_brightness_2.png\n",
      "Hotdog_brightness_2_25.png\n",
      "Circularblur\n",
      "Hotdog_circularBlur_0.bmp\n",
      "Hotdog_circularBlur_1.png\n",
      "Hotdog_circularBlur_10.png\n",
      "Hotdog_circularBlur_2.png\n",
      "Hotdog_circularBlur_3.png\n",
      "Hotdog_circularBlur_4.png\n",
      "Hotdog_circularBlur_5.png\n",
      "Hotdog_circularBlur_7_5.png\n",
      "Dilation\n",
      "Hotdog_dilation_0.bmp\n",
      "Hotdog_dilation_1.png\n",
      "Hotdog_dilation_2.png\n",
      "Hotdog_dilation_3.png\n",
      "Hotdog_dilation_4.png\n",
      "Hotdog_dilation_5.png\n",
      "Hole\n",
      "Hotdog_hole_0.bmp\n",
      "Hotdog_hole_0_01.png\n",
      "Hotdog_hole_0_05.png\n",
      "Hotdog_hole_0_1.png\n",
      "Hotdog_hole_0_15.png\n",
      "Hotdog_hole_0_2.png\n",
      "Hotdog_hole_0_3.png\n",
      "Hotdog_hole_0_4.png\n",
      "Noise\n",
      "Hotdog_noise_0.bmp\n",
      "Hotdog_noise_1.png\n",
      "Hotdog_noise_10.png\n",
      "Hotdog_noise_2.png\n",
      "Hotdog_noise_20.png\n",
      "Hotdog_noise_35.png\n",
      "Hotdog_noise_5.png\n",
      "Hotdog_noise_50.png\n",
      "Rotate\n",
      "Hotdog_rotate_0.bmp\n",
      "Hotdog_rotate_1.png\n",
      "Hotdog_rotate_10.png\n",
      "Hotdog_rotate_15.png\n",
      "Hotdog_rotate_2.png\n",
      "Hotdog_rotate_20.png\n",
      "Hotdog_rotate_3.png\n",
      "Hotdog_rotate_35.png\n",
      "Hotdog_rotate_5.png\n",
      "Saturation\n",
      "Hotdog_saturation_0.bmp\n",
      "Hotdog_saturation_1_05.png\n",
      "Hotdog_saturation_1_1.png\n",
      "Hotdog_saturation_1_15.png\n",
      "Hotdog_saturation_1_2.png\n",
      "Hotdog_saturation_1_5.png\n",
      "Hotdog_saturation_1_75.png\n",
      "Hotdog_saturation_2.png\n",
      "Shift\n",
      "Hotdog_shift_0.bmp\n",
      "Hotdog_shift_0_01.png\n",
      "Hotdog_shift_0_02.png\n",
      "Hotdog_shift_0_05.png\n",
      "Hotdog_shift_0_1.png\n",
      "Hotdog_shift_0_2.png\n",
      "Hotdog_shift_0_3.png\n",
      "Ziemniaki\n",
      "Blur\n",
      "Ziemniaki_blur_0.bmp\n",
      "Ziemniaki_blur_1.png\n",
      "Ziemniaki_blur_10.png\n",
      "Ziemniaki_blur_12_5.png\n",
      "Ziemniaki_blur_15.png\n",
      "Ziemniaki_blur_2.png\n",
      "Ziemniaki_blur_3.png\n",
      "Ziemniaki_blur_5.png\n",
      "Ziemniaki_blur_7_5.png\n",
      "Brightness\n",
      "Ziemniaki_brightness_0.bmp\n",
      "Ziemniaki_brightness_1_02.png\n",
      "Ziemniaki_brightness_1_05.png\n",
      "Ziemniaki_brightness_1_1.png\n",
      "Ziemniaki_brightness_1_2.png\n",
      "Ziemniaki_brightness_1_5.png\n",
      "Ziemniaki_brightness_1_75.png\n",
      "Ziemniaki_brightness_2.png\n",
      "Ziemniaki_brightness_2_25.png\n",
      "Circularblur\n",
      "Ziemniaki_circularBlur_0.bmp\n",
      "Ziemniaki_circularBlur_1.png\n",
      "Ziemniaki_circularBlur_10.png\n",
      "Ziemniaki_circularBlur_2.png\n",
      "Ziemniaki_circularBlur_3.png\n",
      "Ziemniaki_circularBlur_4.png\n",
      "Ziemniaki_circularBlur_5.png\n",
      "Ziemniaki_circularBlur_7.5.png\n",
      "Dilation\n",
      "Ziemniaki_dilation_0.bmp\n",
      "Ziemniaki_dilation_1.png\n",
      "Ziemniaki_dilation_2.png\n",
      "Ziemniaki_dilation_3.png\n",
      "Ziemniaki_dilation_4.png\n",
      "Ziemniaki_dilation_5.png\n",
      "Hole\n",
      "Ziemniaki_hole_0.bmp\n",
      "Ziemniaki_hole_0_01.png\n",
      "Ziemniaki_hole_0_05.png\n",
      "Ziemniaki_hole_0_1.png\n",
      "Ziemniaki_hole_0_15.png\n",
      "Ziemniaki_hole_0_2.png\n",
      "Ziemniaki_hole_0_3.png\n",
      "Ziemniaki_hole_0_4.png\n",
      "Noise\n",
      "Ziemniaki_noise_0.bmp\n",
      "Ziemniaki_noise_1.png\n",
      "Ziemniaki_noise_10.png\n",
      "Ziemniaki_noise_2.png\n",
      "Ziemniaki_noise_20.png\n",
      "Ziemniaki_noise_35.png\n",
      "Ziemniaki_noise_5.png\n",
      "Ziemniaki_noise_50.png\n",
      "Rotate\n",
      "Ziemniaki_rotate_0.bmp\n",
      "Ziemniaki_rotate_1.png\n",
      "Ziemniaki_rotate_10.png\n",
      "Ziemniaki_rotate_15.png\n",
      "Ziemniaki_rotate_2.png\n",
      "Ziemniaki_rotate_20.png\n",
      "Ziemniaki_rotate_3.png\n",
      "Ziemniaki_rotate_35.png\n",
      "Ziemniaki_rotate_5.png\n",
      "Saturation\n",
      "Ziemniaki_saturation_0.bmp\n",
      "Ziemniaki_saturation_1_05.png\n",
      "Ziemniaki_saturation_1_1.png\n",
      "Ziemniaki_saturation_1_15.png\n",
      "Ziemniaki_saturation_1_2.png\n",
      "Ziemniaki_saturation_1_5.png\n",
      "Ziemniaki_saturation_2.png\n",
      "Shift\n",
      "Ziemniaki_shift_0.bmp\n",
      "Ziemniaki_shift_0_01.png\n",
      "Ziemniaki_shift_0_02.png\n",
      "Ziemniaki_shift_0_05.png\n",
      "Ziemniaki_shift_0_1.png\n",
      "Ziemniaki_shift_0_2.png\n",
      "Ziemniaki_shift_0_3.png\n",
      "✅ Results saved to distortion_results.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize LPIPS model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loss_fn = lpips.LPIPS(net='alex').to(device)\n",
    "\n",
    "# Transform: convert image to tensor and normalize to [-1, 1]\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Optional: adjust to match your data\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)  # LPIPS expects input in [-1, 1]\n",
    "])\n",
    "\n",
    "results = []\n",
    "df = None\n",
    "if not recalculate_values:\n",
    "    try:\n",
    "        df = pd.read_csv(csv_output_dir + \"/distortion_results.csv\")\n",
    "    except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        print('Results file not found. Will calculate all values.')\n",
    "        recalculate_values = True\n",
    "\n",
    "uiqi_torch = UniversalImageQualityIndex()\n",
    "vif_torch = VisualInformationFidelity()\n",
    "# Loop over picture folders (Degus, Hotdog, etc.)\n",
    "for scene_folder in os.listdir(distorted_images_dir):\n",
    "    print(scene_folder)\n",
    "    scene_path = os.path.join(distorted_images_dir, scene_folder)\n",
    "    if not os.path.isdir(scene_path):\n",
    "        continue\n",
    "\n",
    "    # Loop over distortion type folders (Blur, Noise, etc.)\n",
    "    for distortion_folder in os.listdir(scene_path):\n",
    "        print(distortion_folder)\n",
    "        distortion_path = os.path.join(scene_path, distortion_folder)\n",
    "        if not os.path.isdir(distortion_path):\n",
    "            continue\n",
    "\n",
    "        # Find ref image (ends with 0.bmp and is only .bmp file)\n",
    "        reference_image_path = None\n",
    "        for file in os.listdir(distortion_path):\n",
    "            if file.endswith('_0.bmp'):\n",
    "                reference_image_path = os.path.join(distortion_path, file)\n",
    "                break\n",
    "        if reference_image_path is None:\n",
    "            print(f\"No reference image found in {scene_path}\")\n",
    "            continue\n",
    "        ref_img_lpips = transform(Image.open(reference_image_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "        ref_img_ssim = cv2.cvtColor(cv2.imread(reference_image_path), cv2.COLOR_BGR2RGB)\n",
    "        ref_img_psnr = cv2.imread(reference_image_path)\n",
    "        \n",
    "\n",
    "        normalized_ref_img = (cv2.imread(reference_image_path).astype(np.float32) / 127.5) - 1.0 \n",
    "\n",
    "        tensor_ref_img = torch.from_numpy(normalized_ref_img).permute(2, 0, 1)\n",
    "\n",
    "\n",
    "\n",
    "        uiqi_torch.reset()\n",
    "        vif_torch.reset()\n",
    "        for file in os.listdir(distortion_path):\n",
    "            print(file)\n",
    "            if not file.endswith('.bmp') and not file.endswith('.png'):\n",
    "                continue\n",
    "\n",
    "            #extract distortion value\n",
    "            distortion_value = -1\n",
    "            match = re.search(r'^([^_]+)_([^_]+)_(.*)\\.(png|bmp)$', file)\n",
    "            try:\n",
    "                distortion_value = float(match.group(3).replace('_', '.'))\n",
    "            except:\n",
    "                print(f\"No distortion value found in {file}\")\n",
    "\n",
    "            # Load and preprocess distorted image\n",
    "            distorted_image_path = os.path.join(distortion_path, file)\n",
    "            df_i = None\n",
    "            if not recalculate_values:\n",
    "                df_i = df[\n",
    "                    (df[\"Picture\"] == scene_folder) &\n",
    "                    (df[\"DistortionType\"] == distortion_folder) &\n",
    "                    (df[\"DistortionValue\"] == distortion_value)\n",
    "                ]\n",
    "            \n",
    "            normalized_distorted_img = (cv2.imread(distorted_image_path).astype(np.float32) / 127.5) - 1.0\n",
    "            tensor_distorted_img = torch.from_numpy(normalized_distorted_img).permute(2, 0, 1)\n",
    "\n",
    "            # Compute LPIPS (lpips) distance\n",
    "            if recalculate_values or df_i[df_i[\"Method\"] == \"LPIPS\"].empty:\n",
    "                dist_img_lpips = transform(Image.open(distorted_image_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "                with torch.no_grad():\n",
    "                    distance_lpips = loss_fn(ref_img_lpips, dist_img_lpips).item()\n",
    "\n",
    "                results.append({\n",
    "                    'Picture': scene_folder,\n",
    "                    'DistortionType': distortion_folder,\n",
    "                    'DistortionValue': distortion_value,\n",
    "                    'Filename': file,\n",
    "                    'Metric': 'LPIPS',\n",
    "                    'Method': 'LPIPS_lpips',\n",
    "                    'Value': distance_lpips\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Skipping {file}, LPIPS is already calculated\")\n",
    "\n",
    "            # Compute SSIM\n",
    "            if recalculate_values or df_i[df_i[\"Method\"] == \"SSIM\"].empty:\n",
    "                dist_img_ssim  = cv2.cvtColor(cv2.imread(distorted_image_path), cv2.COLOR_BGR2RGB)\n",
    "                distance_ssim, _ = ssim_skimage(\n",
    "                    ref_img_ssim,\n",
    "                    dist_img_ssim,\n",
    "                    channel_axis=2,\n",
    "                    full=True\n",
    "                )\n",
    "\n",
    "                results.append({\n",
    "                    'Picture': scene_folder,\n",
    "                    'DistortionType': distortion_folder,\n",
    "                    'DistortionValue': distortion_value,\n",
    "                    'Filename': file,\n",
    "                    'Metric': 'SSIM',\n",
    "                    'Method': 'SSIM_skimage',\n",
    "                    'Value': distance_ssim\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Skipping {file}, SSIM is already calculated\")\n",
    "\n",
    "            if recalculate_values or df_i[df_i[\"Method\"] == \"PSNR\"].empty:\n",
    "                # Compute PSNR value\n",
    "                dist_img_psnr  = cv2.imread(distorted_image_path)\n",
    "                distance_psnr = psnr(ref_img_psnr, dist_img_psnr, data_range=255)\n",
    "                results.append({\n",
    "                    'Picture': scene_folder,\n",
    "                    'DistortionType': distortion_folder,\n",
    "                    'DistortionValue': distortion_value,\n",
    "                    'Filename': file,\n",
    "                    'Metric': 'PSNR',\n",
    "                    'Method': 'PSNR_skimage',\n",
    "                    'Value': distance_psnr\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Skipping {file}, PSNR is already calculated\")\n",
    "\n",
    "            # Compute UIQI\n",
    "            if recalculate_values or df_i[df_i[\"Method\"] == \"UIQI\"].empty:\n",
    "                # Compute UIQI value\n",
    "                distance_UIQI = uiqi_torch(tensor_ref_img.expand(1,-1,-1,-1), tensor_distorted_img.expand(1,-1,-1,-1))\n",
    "                results.append({\n",
    "                    'Picture': scene_folder,\n",
    "                    'DistortionType': distortion_folder,\n",
    "                    'DistortionValue': distortion_value,\n",
    "                    'Filename': file,\n",
    "                    'Metric': 'UIQI',\n",
    "                    'Method': 'UIQI_torch',\n",
    "                    'Value': distance_UIQI.item()\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Skipping {file}, UIQI is already calculated\")\n",
    "\n",
    "            # Compute VIF\n",
    "            if recalculate_values or df_i[df_i[\"Method\"] == \"VIF\"].empty:\n",
    "                # Compute VIF value\n",
    "                distance_VIF = vif_torch(tensor_ref_img.expand(1,-1,-1,-1), tensor_distorted_img.expand(1,-1,-1,-1))\n",
    "                results.append({\n",
    "                    'Picture': scene_folder,\n",
    "                    'DistortionType': distortion_folder,\n",
    "                    'DistortionValue': distortion_value,\n",
    "                    'Filename': file,\n",
    "                    'Metric': 'VIF',\n",
    "                    'Method': 'VIF_torch',\n",
    "                    'Value': distance_VIF.item()\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Skipping {file}, VIF is already calculated\")\n",
    "\n",
    "\n",
    "# Save all results to CSV\n",
    "df_new = pd.DataFrame(results)\n",
    "os.makedirs(csv_output_dir, exist_ok=True)\n",
    "csv_path = os.path.join(csv_output_dir, 'distortion_results.csv')\n",
    "file_exists = os.path.isfile(csv_path)\n",
    "df_new.to_csv(csv_path, mode='a', header=not file_exists, index=False)\n",
    "print(\"✅ Results saved to distortion_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d1d8c5",
   "metadata": {},
   "source": [
    "# NULCEAR EMERGENCY: USE IF METRICS ARE FUCKED UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dfb454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piotr\\AppData\\Local\\Temp\\ipykernel_17436\\3478999076.py:14: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(strip_tensor_string)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Function to extract the float from a string like \"tensor(6.8433)\"\n",
    "def strip_tensor_string(val):\n",
    "    if isinstance(val, str) and val.startswith('tensor(') and val.endswith(')'):\n",
    "        try:\n",
    "            return float(val[len('tensor('):-1])\n",
    "        except ValueError:\n",
    "            return val  # leave unchanged if it can't be converted\n",
    "    return val  # leave unchanged if not a tensor string\n",
    "\n",
    "# Apply the function to all cells\n",
    "csv_path_cleaned = os.path.join(csv_output_dir, 'distortion_results_cleaned.csv')\n",
    "df = df.applymap(strip_tensor_string)\n",
    "\n",
    "df.loc[df.index % 5 == 4, 'Metric'] = 'VIF'\n",
    "df.loc[df.index % 5 == 4, 'Method'] = 'VIF_Torch'\n",
    "\n",
    "# Optional: Save to a new CSV\n",
    "df.to_csv(csv_path_cleaned, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Creating charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piotr\\AppData\\Local\\Temp\\ipykernel_17436\\541571912.py:42: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend(title='Picture', fontsize='small')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All charts saved\n"
     ]
    }
   ],
   "source": [
    "# === Load CSV ===\n",
    "df = pd.read_csv(csv_output_dir + \"/distortion_results_cleaned.csv\")\n",
    "\n",
    "# Add synthetic LPIPS=0 for level 0 reference images\n",
    "reference_rows = []\n",
    "for picture in df['Picture'].unique():\n",
    "    for distortion in df['DistortionType'].unique():\n",
    "        value = 0\n",
    "        if(distortion == 'Brightness' or distortion == 'Saturation'):\n",
    "            value = 1\n",
    "        reference_rows.append({\n",
    "            'Picture': picture,\n",
    "            'DistortionType': distortion,\n",
    "            'DistortionValue': value,\n",
    "            'Filename': 'image_0.bmp',\n",
    "            'Method': 'LPIPS',\n",
    "            'Value': 0.0\n",
    "        })\n",
    "\n",
    "df = pd.concat([df, pd.DataFrame(reference_rows)], ignore_index=True)\n",
    "# === Plotting ===\n",
    "os.makedirs(chart_output_dir, exist_ok=True)\n",
    "\n",
    "for method in df['Metric'].unique():\n",
    "    method_df = df[df['Metric'] == method]\n",
    "    for distortion in df['DistortionType'].unique():\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        distortion_df = method_df[method_df['DistortionType'] == distortion]\n",
    "\n",
    "        for picture in sorted(distortion_df['Picture'].unique()):\n",
    "            picture_df = distortion_df[distortion_df['Picture'] == picture]\n",
    "            picture_df = picture_df.sort_values('DistortionValue')\n",
    "\n",
    "            # Build y and x values\n",
    "            x = picture_df['DistortionValue']\n",
    "            y = picture_df['Value']\n",
    "            plt.plot(x, y, marker='o', label=picture)\n",
    "\n",
    "        plt.title(f'{method} vs Distortion Value – {distortion}')\n",
    "        plt.xlabel('Distortion Parameter')\n",
    "        plt.ylabel(f'{method} Distance')\n",
    "        plt.legend(title='Picture', fontsize='small')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        os.makedirs(f'{chart_output_dir}/{method}', exist_ok=True)\n",
    "        plt.savefig(f'{chart_output_dir}/{method}/{distortion}_{method}_chart.png')\n",
    "        plt.close()\n",
    "\n",
    "print(\"✅ All charts saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Creating group chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_output_dir + \"/distortion_results.csv\")\n",
    "\n",
    "# Keep rows with the highest DistortionValue for each Picture & DistortionType\n",
    "idx = df.groupby(['Picture', 'DistortionType'])['DistortionValue'].idxmax()\n",
    "df_max_distortions = df.loc[idx]\n",
    "df_max_distortions['DistortionLabel'] = df_max_distortions.apply(lambda row: f\"{row['DistortionType']} ({row['DistortionValue']})\", axis=1)\n",
    "\n",
    "# Pivot for grouped bar chart: index=DistortionType, columns=Picture, values=LPIPS\n",
    "pivot_df = df_max_distortions.pivot(index='DistortionLabel', columns='Picture', values='Value')\n",
    "\n",
    "# Plot\n",
    "pivot_df.plot(kind='bar', figsize=(10, 6))\n",
    "\n",
    "plt.ylabel('LPIPS Distance')\n",
    "plt.title('LPIPS at Max Distortion per Picture per Distortion Type')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Picture')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{chart_output_dir}/lpips_distortion_max.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd75f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset if needed (skip if already loaded)\n",
    "# df = pd.read_csv(csv_output_dir + \"/distortion_results.csv\")\n",
    "\n",
    "# List of images to process\n",
    "pictures = ['Degus', 'Hotdog', 'Ziemniaki']\n",
    "\n",
    "for picture in pictures:\n",
    "    df_pic = df[df['Picture'] == picture]\n",
    "\n",
    "    # Get max distortion per distortion type and metric\n",
    "    idx = df_pic.groupby(['DistortionType', 'Metric'])['DistortionValue'].idxmax()\n",
    "    df_pic_max = df_pic.loc[idx]\n",
    "\n",
    "    # Create label like \"Blur (5.0)\"\n",
    "    df_pic_max['DistortionLabel'] = df_pic_max.apply(\n",
    "        lambda row: f\"{row['DistortionType']} ({row['DistortionValue']})\", axis=1\n",
    "    )\n",
    "\n",
    "    # Pivot: rows = distortion labels, columns = metrics, values = metric values\n",
    "    pivot_df = df_pic_max.pivot(index='DistortionLabel', columns='Metric', values='Value')\n",
    "\n",
    "    # Ensure column order is LPIPS, PSNR, SSIM (if present)\n",
    "    desired_order = ['LPIPS', 'PSNR', 'SSIM']\n",
    "    pivot_df = pivot_df[[col for col in desired_order if col in pivot_df.columns]]\n",
    "\n",
    "    # Normalize each metric independently (column-wise)\n",
    "    normalized_df = pivot_df / pivot_df.max()\n",
    "\n",
    "    # Plot\n",
    "    ax = normalized_df.plot(kind='bar', figsize=(10, 6))\n",
    "    plt.ylabel('Normalized Metric Value')\n",
    "    plt.title(f'Normalized Metrics at Max Distortion per Distortion Type for \"{picture}\"')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.legend(title='Metric')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{chart_output_dir}/{picture.lower()}_normalized_metrics.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511c4cd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# List of pictures to average\n",
    "pictures = ['Degus', 'Hotdog', 'Ziemniaki']\n",
    "all_rows = []\n",
    "\n",
    "# Collect max distortion rows for each image\n",
    "for picture in pictures:\n",
    "    df_pic = df[df['Picture'] == picture]\n",
    "    idx = df_pic.groupby(['DistortionType', 'Method'])['DistortionValue'].idxmax()\n",
    "    df_pic_max = df_pic.loc[idx].copy()\n",
    "    df_pic_max['Picture'] = picture  # Ensure Picture label is preserved\n",
    "    all_rows.append(df_pic_max)\n",
    "\n",
    "# Combine all into one DataFrame\n",
    "df_all = pd.concat(all_rows)\n",
    "\n",
    "# Add DistortionLabel for grouping\n",
    "df_all['DistortionLabel'] = df_all.apply(\n",
    "    lambda row: f\"{row['DistortionType']} ({row['DistortionValue']})\", axis=1\n",
    ")\n",
    "\n",
    "# Pivot: rows = (DistortionLabel, Picture), columns = Metric, values = Value\n",
    "pivot = df_all.pivot_table(index=['DistortionLabel', 'Picture'], columns='Method', values='Value')\n",
    "\n",
    "# Average across pictures per DistortionLabel\n",
    "pivot_avg = pivot.groupby('DistortionLabel').mean()\n",
    "\n",
    "# Ensure consistent metric order\n",
    "desired_order = ['LPIPS', 'PSNR', 'SSIM']\n",
    "pivot_avg = pivot_avg[[col for col in desired_order if col in pivot_avg.columns]]\n",
    "\n",
    "# Normalize each metric individually\n",
    "pivot_avg_norm = pivot_avg / pivot_avg.max()\n",
    "\n",
    "# Plot\n",
    "ax = pivot_avg_norm.plot(kind='bar', figsize=(10, 6))\n",
    "plt.ylabel('Normalized Average Metric Value')\n",
    "plt.title('Normalized Average Metrics at Max Distortion per Distortion Type (All Images)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(title='Metric')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{chart_output_dir}/average_normalized_metrics.png\")\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
